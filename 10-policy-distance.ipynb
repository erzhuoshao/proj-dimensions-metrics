{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ac2c01",
   "metadata": {},
   "source": [
    "### **Policy Distance**\n",
    "\n",
    "**Reference:**\n",
    " - Ahmadpoor, Mohammad, and Benjamin F. Jones. \"The dual frontier: Patented inventions and prior scientific advance.\" Science 357.6351 (2017): 583-587.\n",
    "\n",
    "**Note:** This notebook calculates the policy distance metric following the same methodology as patent distance, but using policy-paper citations instead of patent-paper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fgbg5c07ei5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# Configure tqdm for better progress bars\n",
    "tqdm.pandas(ncols=100, mininterval=1)\n",
    "tqdm = partial(tqdm, ncols=100, mininterval=1)\n",
    "trange = partial(trange, ncols=100, mininterval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daff476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18,409,473 policy-paper citation records\n",
      "Unique policies: 1,007,973\n",
      "Unique DOIs: 5,734,162\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>policy_document_id</th>\n",
       "      <th>dois_cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jiia-121176f43125848e5c73e939291a1829</td>\n",
       "      <td>10.1080/24761028.2014.11869071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>jiia-121176f43125848e5c73e939291a1829</td>\n",
       "      <td>10.2307/2750627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>jiia-1a118bd53fea6bd1b335adcf8fd16904</td>\n",
       "      <td>10.2307/2050758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>jiia-1f818b4973fab3ff09462ef5dc7dcb25</td>\n",
       "      <td>10.1177/097492848103700103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>jiia-1f818b4973fab3ff09462ef5dc7dcb25</td>\n",
       "      <td>10.1525/as.1997.37.4.01p0237s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     policy_document_id  \\\n",
       "0           0  jiia-121176f43125848e5c73e939291a1829   \n",
       "1           0  jiia-121176f43125848e5c73e939291a1829   \n",
       "2           1  jiia-1a118bd53fea6bd1b335adcf8fd16904   \n",
       "3           2  jiia-1f818b4973fab3ff09462ef5dc7dcb25   \n",
       "4           2  jiia-1f818b4973fab3ff09462ef5dc7dcb25   \n",
       "\n",
       "                       dois_cited  \n",
       "0  10.1080/24761028.2014.11869071  \n",
       "1                 10.2307/2750627  \n",
       "2                 10.2307/2050758  \n",
       "3      10.1177/097492848103700103  \n",
       "4   10.1525/as.1997.37.4.01p0237s  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load policy-paper DOI mapping\n",
    "policy_to_doi = pd.read_csv('/kellogg/proj/dashun/policy/general/20240202/df_policy_to_doi.csv')\n",
    "\n",
    "print(f\"Loaded {len(policy_to_doi):,} policy-paper citation records\")\n",
    "print(f\"Unique policies: {policy_to_doi['policy_document_id'].nunique():,}\")\n",
    "print(f\"Unique DOIs: {policy_to_doi['dois_cited'].nunique():,}\")\n",
    "print(\"\\nSample data:\")\n",
    "policy_to_doi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mm58akvycy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading publications data...\n",
      "Total papers: 152,387,558\n",
      "Papers with DOI: 144,556,840\n",
      "Created DOI to paper_id mapping with 144,456,093 entries\n"
     ]
    }
   ],
   "source": [
    "# Load publications data and create DOI to paper_id mapping\n",
    "# Note: paper id in Dimensions is formatted as \"pub.XXXXXXXXX\"\n",
    "print(\"Loading publications data...\")\n",
    "papers = pd.read_feather(\"../parquet/processed/publications.feather\")\n",
    "\n",
    "# Create DOI to paper_id mapping (only for papers with DOI)\n",
    "papers_with_doi = papers[papers['doi'].notna()][['id', 'doi']]\n",
    "print(f\"Total papers: {len(papers):,}\")\n",
    "print(f\"Papers with DOI: {len(papers_with_doi):,}\")\n",
    "\n",
    "# Convert DOI to lowercase for case-insensitive matching\n",
    "papers_with_doi['doi_lower'] = papers_with_doi['doi'].str.lower()\n",
    "\n",
    "# Create mapping dict: doi -> paper_id (as integer)\n",
    "# paper_id format is \"pub.XXXXXXXXX\", we extract the numeric part\n",
    "papers_with_doi['paper_id'] = papers_with_doi['id'].str[4:].astype(int)\n",
    "doi_to_paper_id = papers_with_doi.set_index('doi_lower')['paper_id'].to_dict()\n",
    "\n",
    "print(f\"Created DOI to paper_id mapping with {len(doi_to_paper_id):,} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jncpzo4ypqp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total policy-paper citations: 18,409,473\n",
      "Successfully mapped to paper_id: 17,361,459 (94.31%)\n",
      "Unmapped (DOI not found in Dimensions): 1,048,014\n",
      "\n",
      "Unique papers cited by policies: 5,282,873\n",
      "Unique policies citing papers: 953,146\n"
     ]
    }
   ],
   "source": [
    "# Map policy DOIs to paper_ids\n",
    "policy_to_doi['doi_lower'] = policy_to_doi['dois_cited'].str.lower()\n",
    "policy_to_doi['paper_id'] = policy_to_doi['doi_lower'].map(doi_to_paper_id)\n",
    "\n",
    "# Check mapping success rate\n",
    "total_citations = len(policy_to_doi)\n",
    "mapped_citations = policy_to_doi['paper_id'].notna().sum()\n",
    "print(f\"Total policy-paper citations: {total_citations:,}\")\n",
    "print(f\"Successfully mapped to paper_id: {mapped_citations:,} ({mapped_citations/total_citations*100:.2f}%)\")\n",
    "print(f\"Unmapped (DOI not found in Dimensions): {total_citations - mapped_citations:,}\")\n",
    "\n",
    "# Get unique papers cited by policies\n",
    "paper_policies = policy_to_doi[policy_to_doi['paper_id'].notna()][['paper_id', 'policy_document_id']].copy()\n",
    "paper_policies['paper_id'] = paper_policies['paper_id'].astype(int)\n",
    "\n",
    "print(f\"\\nUnique papers cited by policies: {paper_policies['paper_id'].nunique():,}\")\n",
    "print(f\"Unique policies citing papers: {paper_policies['policy_document_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mat34pk6hf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded citation network with 77,933,004 citing papers\n"
     ]
    }
   ],
   "source": [
    "# Load citation network: citing_paper_id -> [(cited_paper_id, year), ...]\n",
    "dict_citing_to_cited_id_and_year = pd.read_feather(\"intermediate/dict_citing_to_cited_id_and_year.feather\")\n",
    "dict_citing_to_cited_id_and_year = dict_citing_to_cited_id_and_year.set_index(\"citing_paperid\").cited_list.to_dict()\n",
    "print(f\"Loaded citation network with {len(dict_citing_to_cited_id_and_year):,} citing papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ai26l8256h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance   New Papers      Cumulative Papers   \n",
      "---------------------------------------------\n",
      "Policies   953,146         -                   \n",
      "1          5,282,873       5,282,873           \n",
      "2          17,997,999      23,280,872          \n",
      "3          19,013,681      42,294,553          \n",
      "4          9,145,288       51,439,841          \n",
      "5          3,580,845       55,020,686          \n",
      "6          1,520,268       56,540,954          \n",
      "7          744,998         57,285,952          \n",
      "8          417,122         57,703,074          \n",
      "9          266,724         57,969,798          \n",
      "10         189,095         58,158,893          \n",
      "11         144,956         58,303,849          \n",
      "12         119,871         58,423,720          \n",
      "13         103,497         58,527,217          \n",
      "14         94,636          58,621,853          \n",
      "15         86,445          58,708,298          \n",
      "16         77,618          58,785,916          \n",
      "17         64,059          58,849,975          \n",
      "18         49,968          58,899,943          \n",
      "19         39,157          58,939,100          \n",
      "20         30,027          58,969,127          \n",
      "21         22,548          58,991,675          \n",
      "22         14,885          59,006,560          \n",
      "23         9,039           59,015,599          \n",
      "24         5,622           59,021,221          \n",
      "25         3,876           59,025,097          \n",
      "26         3,035           59,028,132          \n",
      "27         2,550           59,030,682          \n",
      "28         2,204           59,032,886          \n",
      "29         1,540           59,034,426          \n",
      "30         1,032           59,035,458          \n",
      "31         751             59,036,209          \n",
      "32         421             59,036,630          \n",
      "33         233             59,036,863          \n",
      "34         116             59,036,979          \n",
      "35         57              59,037,036          \n",
      "36         37              59,037,073          \n",
      "37         26              59,037,099          \n",
      "38         28              59,037,127          \n",
      "39         27              59,037,154          \n",
      "40         19              59,037,173          \n",
      "41         12              59,037,185          \n",
      "42         7               59,037,192          \n",
      "43         1               59,037,193          \n",
      "44         0               59,037,193          \n",
      "\n",
      "BFS completed: No new papers found at distance 44\n",
      "Maximum distance reached: 43\n",
      "Total papers discovered: 59,037,193\n"
     ]
    }
   ],
   "source": [
    "# Initialize BFS\n",
    "# Distance 1: All papers cited by policies (starting point)\n",
    "papers_with_policies = set(paper_policies['paper_id'].unique().tolist())\n",
    "distance_to_papers = [papers_with_policies]  # distance_to_papers[0] = papers at distance 1\n",
    "\n",
    "# Track all papers we've already discovered to avoid revisiting\n",
    "discovered_papers = papers_with_policies.copy()\n",
    "\n",
    "# Number of unique policies (source)\n",
    "num_policies = paper_policies['policy_document_id'].nunique()\n",
    "\n",
    "print(f\"{'Distance':<10} {'New Papers':<15} {'Cumulative Papers':<20}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Policies':<10} {num_policies:<15,} {'-':<20}\")\n",
    "print(f\"{1:<10} {len(papers_with_policies):<15,} {len(discovered_papers):<20,}\")\n",
    "\n",
    "# Maximum iterations to prevent infinite loops\n",
    "MAX_DISTANCE = 100\n",
    "\n",
    "# BFS traversal\n",
    "for distance in range(MAX_DISTANCE):\n",
    "    current_distance = distance + 2  # We start at distance 1, so next is 2\n",
    "    \n",
    "    # Find all papers that cite papers at the previous distance level\n",
    "    papers_at_prev_distance = distance_to_papers[-1]\n",
    "    papers_at_current_distance = []\n",
    "    \n",
    "    for citing_paper_id in papers_at_prev_distance:\n",
    "        # Get all papers cited by this paper\n",
    "        cited_list = dict_citing_to_cited_id_and_year.get(citing_paper_id, [])\n",
    "        cited_paper_ids = [cited_paper_id for cited_paper_id, year in cited_list]\n",
    "        papers_at_current_distance.extend(cited_paper_ids)\n",
    "    \n",
    "    papers_at_current_distance = set(papers_at_current_distance) - discovered_papers\n",
    "    discovered_papers.update(papers_at_current_distance) \n",
    "    distance_to_papers.append(papers_at_current_distance)\n",
    "    \n",
    "    # Log progress\n",
    "    print(f\"{current_distance:<10} {len(papers_at_current_distance):<15,} {len(discovered_papers):<20,}\")\n",
    "    \n",
    "    # Stop if no new papers found\n",
    "    if len(papers_at_current_distance) == 0:\n",
    "        print(f\"\\nBFS completed: No new papers found at distance {current_distance}\")\n",
    "        print(f\"Maximum distance reached: {current_distance - 1}\")\n",
    "        print(f\"Total papers discovered: {len(discovered_papers):,}\")\n",
    "        break\n",
    "else:\n",
    "    # Only print warning if we actually hit the MAX_DISTANCE limit\n",
    "    print(f\"\\nWarning: Reached maximum distance limit ({MAX_DISTANCE})\")\n",
    "    print(f\"Total papers discovered: {len(discovered_papers):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "do4zafc3bzj",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building records: 100%|█████████████████████████████████████████████| 44/44 [03:35<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 59,037,193 paper-distance records\n",
      "Dataset Summary:\n",
      "  Total papers: 59,037,193\n",
      "  Distance range: 1 - 43\n",
      "\n",
      "Distance distribution:\n",
      "distance\n",
      "1      5282873\n",
      "2     17997999\n",
      "3     19013681\n",
      "4      9145288\n",
      "5      3580845\n",
      "6      1520268\n",
      "7       744998\n",
      "8       417122\n",
      "9       266724\n",
      "10      189095\n",
      "11      144956\n",
      "12      119871\n",
      "13      103497\n",
      "14       94636\n",
      "15       86445\n",
      "16       77618\n",
      "17       64059\n",
      "18       49968\n",
      "19       39157\n",
      "20       30027\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Data saved.\n"
     ]
    }
   ],
   "source": [
    "# Build list of (paper_id, distance) tuples\n",
    "paper_policy_distance_df = []\n",
    "\n",
    "# Skip the last element (empty set from termination condition)\n",
    "for distance_idx in trange(len(distance_to_papers), desc=\"Building records\"):\n",
    "    distance = distance_idx + 1  # Actual distance value\n",
    "    papers_at_distance = distance_to_papers[distance_idx]\n",
    "    \n",
    "    for paper_id in papers_at_distance:\n",
    "        paper_policy_distance_df.append([paper_id, distance])\n",
    "\n",
    "print(f\"\\nCreated {len(paper_policy_distance_df):,} paper-distance records\")\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "paper_policy_distance_df = pd.DataFrame(\n",
    "    paper_policy_distance_df, \n",
    "    columns=['paper_id', 'distance'],\n",
    ").astype({'paper_id': 'int64', 'distance': 'int64'})\n",
    "\n",
    "paper_policy_distance_df[\"paper_id\"] = \"pub.\" + paper_policy_distance_df[\"paper_id\"].astype(str)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"  Total papers: {len(paper_policy_distance_df):,}\")\n",
    "print(f\"  Distance range: {paper_policy_distance_df['distance'].min()} - {paper_policy_distance_df['distance'].max()}\")\n",
    "print(f\"\\nDistance distribution:\")\n",
    "print(paper_policy_distance_df['distance'].value_counts().sort_index().head(20))\n",
    "\n",
    "paper_policy_distance_df.to_parquet(\"data/paper_policy_distance.parquet\")\n",
    "paper_policy_distance_df.to_feather(\"data/paper_policy_distance.feather\")\n",
    "print(\"\\n\\nData saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479103e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
