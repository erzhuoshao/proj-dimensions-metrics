{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dc2a6b",
   "metadata": {},
   "source": [
    "### **Disruptiveness**\n",
    "\n",
    "Disruptiveness measures how much a paper changes the direction of research in its field. A disruptive paper is one that causes future work to cite it without also citing its references, suggesting it has created a new research direction. In contrast, a consolidating paper is one that future work cites along with its references, suggesting it has built upon and integrated existing knowledge.\n",
    "\n",
    "For each paper, we:\n",
    "1. Identify all papers that cite the focal paper (T) and all papers that cite the focal paper's references (S)\n",
    "2. Calculate three sets:\n",
    "   - n_i: papers that cite the focal paper but not its references (disruptive citations)\n",
    "   - n_j: papers that cite both the focal paper and its references (consolidating citations)\n",
    "   - n_k: papers that cite the focal paper's references but not the focal paper\n",
    "3. Compute the disruption index: D = (n_i - n_j) / (n_i + n_j + n_k)\n",
    "4. Calculate this for multiple time windows (3, 5, 10 years, and all time)\n",
    "\n",
    "The disruption index ranges from -1 (highly consolidating) to +1 (highly disruptive), with 0 indicating a neutral impact.\n",
    "\n",
    "**Reference:**\n",
    " - Funk, Russell J., and Jason Owen-Smith. \"A dynamic network measure of technological change.\" Management science 63.3 (2017): 791-817.\n",
    " - Wu, Lingfei, Dashun Wang, and James A. Evans. \"Large teams develop and small teams disrupt science and technology.\" Nature 566.7744 (2019): 378-382."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as pltnnnnn\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import json, pickle as pkl\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import product, combinations\n",
    "from copy import deepcopy\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "import shutil, os\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas(ncols=100, mininterval=1)\n",
    "tqdm, trange = partial(tqdm, ncols=100, mininterval=1), partial(trange, ncols=100, mininterval=1)\n",
    "\n",
    "references = pd.read_feather('intermediate/citing_cited_paper_id_year.feather')\n",
    "\n",
    "# Dict Structure: {citing_paperid (int): citing_year (int)}\n",
    "dict_paper_id_to_year = (\n",
    "    references\n",
    "    .set_index('citing_paperid')\n",
    "    ['citing_year']\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Dict Structure: {citing_paperid (int): [list of cited_paperids (int)]}\n",
    "Dict_Citing_to_Cited = (\n",
    "    references\n",
    "    .groupby('citing_paperid')\n",
    "    .cited_paperid\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Dict Structure: {cited_paperid (int): {citing_paperid (int): citing_year (int)}}\n",
    "Dict_Cited_to_Citing = (\n",
    "    references\n",
    "    .groupby('cited_paperid')\n",
    "    [['citing_paperid', 'citing_year']]\n",
    "    .apply(lambda x: {id: year for id, year in zip(x.citing_paperid, x.citing_year)})\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "def paper_id_to_disruptiveness(focal_paper_id, future_windows=[3, 5, 10, np.inf]):\n",
    "    # For each paper in cited list, indicating at least one citation.\n",
    "    focal_paper_year = dict_paper_id_to_year[focal_paper_id]\n",
    "    \n",
    "    ref_paper_ids = Dict_Citing_to_Cited.get(focal_paper_id, [])\n",
    "\n",
    "    if len(ref_paper_ids) > 0:\n",
    "        S = {}\n",
    "        for ref_paper_id in ref_paper_ids:\n",
    "            S.update(Dict_Cited_to_Citing.get(ref_paper_id, {}))\n",
    "\n",
    "        T = Dict_Cited_to_Citing.get(focal_paper_id, {})\n",
    "        \n",
    "        results = {\n",
    "            \"paper_id\": f\"pub.{focal_paper_id}\", \n",
    "            \"year\": focal_paper_year, \n",
    "            \"times_cited\": len(T), \n",
    "            \"num_references\": len(ref_paper_ids)\n",
    "        }\n",
    "\n",
    "        for w in future_windows:\n",
    "            # papers who cite focal paper's reference within N years\n",
    "            Sw = {id for id, year in S.items() if (year >= focal_paper_year) and (year <= focal_paper_year + w)}\n",
    "            # papers who cite focal paper within N years\n",
    "            Tw = {id for id, year in T.items() if (year >= focal_paper_year) and (year <= focal_paper_year + w)}\n",
    "            \n",
    "            n_j_w = len(Tw & Sw) # By definition: # papers who cite focal paper and focal paper's reference\n",
    "            n_i_w = len(Tw) - n_j_w # By definition: # papers who cite focal paper without citing focal paper's reference\n",
    "            n_k_w = len(Sw) - n_j_w # By definition: # papers who cite focal paper's reference without citing focal paper\n",
    "\n",
    "            if n_i_w + n_j_w + n_k_w == 0:\n",
    "                D = None\n",
    "            else:\n",
    "                D = (n_i_w - n_j_w) / (n_i_w + n_j_w + n_k_w)\n",
    "\n",
    "            results.update({f\"n_i_{w}\": n_i_w, f\"n_j_{w}\": n_j_w, f\"n_k_{w}\": n_k_w, f\"CD{w}\": D})\n",
    "    else:\n",
    "        for w in future_windows:\n",
    "            results.update({f\"n_i_{w}\": pd.NA, f\"n_j_{w}\": pd.NA, f\"n_k_{w}\": pd.NA, f\"CD{w}\": pd.NA})\n",
    "    return results\n",
    "\n",
    "papers = list(dict_paper_id_to_year.keys())\n",
    "batch_size = 500_000\n",
    "path = f\"intermediate/disruptiveness\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "for idx in trange(0, len(papers), batch_size):\n",
    "    file_path = os.path.join(path, f\"{idx}.feather\")\n",
    "    if not os.path.exists(file_path):\n",
    "        results = process_map(paper_id_to_disruptiveness, papers[idx:idx+batch_size], max_workers=20, chunksize=1000)\n",
    "        results = pd.DataFrame(results)\n",
    "        results.to_feather(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2dcaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
