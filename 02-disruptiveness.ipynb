{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dc2a6b",
   "metadata": {},
   "source": [
    "### **Disruptiveness**\n",
    "\n",
    "Disruptiveness measures how much a paper changes the direction of research in its field. A disruptive paper is one that causes future work to cite it without also citing its references, suggesting it has created a new research direction. In contrast, a consolidating paper is one that future work cites along with its references, suggesting it has built upon and integrated existing knowledge.\n",
    "\n",
    "For each paper, we:\n",
    "1. Identify all papers that cite the focal paper (T) and all papers that cite the focal paper's references (S)\n",
    "2. Calculate three sets:\n",
    "   - n_i: papers that cite the focal paper but not its references (disruptive citations)\n",
    "   - n_j: papers that cite both the focal paper and its references (consolidating citations)\n",
    "   - n_k: papers that cite the focal paper's references but not the focal paper\n",
    "3. Compute the disruption index: D = (n_i - n_j) / (n_i + n_j + n_k)\n",
    "4. Calculate this for multiple time windows (3, 5, 10 years, and all time)\n",
    "\n",
    "The disruption index ranges from -1 (highly consolidating) to +1 (highly disruptive), with 0 indicating a neutral impact.\n",
    "\n",
    "**Reference:**\n",
    " - Funk, Russell J., and Jason Owen-Smith. \"A dynamic network measure of technological change.\" Management science 63.3 (2017): 791-817.\n",
    " - Wu, Lingfei, Dashun Wang, and James A. Evans. \"Large teams develop and small teams disrupt science and technology.\" Nature 566.7744 (2019): 378-382."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6fa86",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd, numpy as np\nfrom matplotlib import pyplot as plt\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 100)\n\nimport json, pickle as pkl\nfrom glob import glob\nfrom collections import Counter, defaultdict\nfrom itertools import product, combinations\nfrom copy import deepcopy\nfrom tqdm.contrib.concurrent import process_map\nimport shutil, os\n\nfrom functools import partial\nfrom tqdm import tqdm, trange\ntqdm.pandas(ncols=100, mininterval=1)\ntqdm, trange = partial(tqdm, ncols=100, mininterval=1), partial(trange, ncols=100, mininterval=1)\n\nreferences = pd.read_feather('intermediate/citing_cited_paper_id_year.feather')\n\n# Dict Structure: {citing_paperid (int): citing_year (int)}\ndict_paper_id_to_year = (\n    references\n    .set_index('citing_paperid')\n    ['citing_year']\n    .to_dict()\n)\n\n# Dict Structure: {citing_paperid (int): [list of cited_paperids (int)]}\nDict_Citing_to_Cited = (\n    references\n    .groupby('citing_paperid')\n    .cited_paperid\n    .apply(list)\n    .to_dict()\n)\n\n# Dict Structure: {cited_paperid (int): {citing_paperid (int): citing_year (int)}}\nDict_Cited_to_Citing = (\n    references\n    .groupby('cited_paperid')\n    [['citing_paperid', 'citing_year']]\n    .apply(lambda x: {id: year for id, year in zip(x.citing_paperid, x.citing_year)})\n    .to_dict()\n)\n\n\ndef paper_id_to_disruptiveness(focal_paper_id, future_windows=[3, 5, 10, np.inf]):\n    # For each paper in cited list, indicating at least one citation.\n    focal_paper_year = dict_paper_id_to_year[focal_paper_id]\n    \n    ref_paper_ids = Dict_Citing_to_Cited.get(focal_paper_id, [])\n    T = Dict_Cited_to_Citing.get(focal_paper_id, {})\n    \n    results = {\n        \"paper_id\": f\"pub.{focal_paper_id}\", \n        \"year\": focal_paper_year, \n        \"times_cited\": len(T), \n        \"num_references\": len(ref_paper_ids)\n    }\n\n    if len(ref_paper_ids) > 0:\n        S = {}\n        for ref_paper_id in ref_paper_ids:\n            S.update(Dict_Cited_to_Citing.get(ref_paper_id, {}))\n\n        for w in future_windows:\n            # papers who cite focal paper's reference within N years\n            Sw = {id for id, year in S.items() if (year >= focal_paper_year) and (year <= focal_paper_year + w)}\n            # papers who cite focal paper within N years\n            Tw = {id for id, year in T.items() if (year >= focal_paper_year) and (year <= focal_paper_year + w)}\n            \n            n_j_w = len(Tw & Sw) # By definition: # papers who cite focal paper and focal paper's reference\n            n_i_w = len(Tw) - n_j_w # By definition: # papers who cite focal paper without citing focal paper's reference\n            n_k_w = len(Sw) - n_j_w # By definition: # papers who cite focal paper's reference without citing focal paper\n\n            if n_i_w + n_j_w + n_k_w == 0:\n                D = None\n            else:\n                D = (n_i_w - n_j_w) / (n_i_w + n_j_w + n_k_w)\n\n            results.update({f\"n_i_{w}\": n_i_w, f\"n_j_{w}\": n_j_w, f\"n_k_{w}\": n_k_w, f\"CD{w}\": D})\n    else:\n        for w in future_windows:\n            results.update({f\"n_i_{w}\": pd.NA, f\"n_j_{w}\": pd.NA, f\"n_k_{w}\": pd.NA, f\"CD{w}\": pd.NA})\n    return results\n\npapers = list(dict_paper_id_to_year.keys())\nbatch_size = 500_000\npath = f\"intermediate/disruptiveness\"\nos.makedirs(path, exist_ok=True)\nfor idx in trange(0, len(papers), batch_size):\n    file_path = os.path.join(path, f\"{idx}.feather\")\n    if not os.path.exists(file_path):\n        results = process_map(paper_id_to_disruptiveness, papers[idx:idx+batch_size], max_workers=20, chunksize=1000)\n        results = pd.DataFrame(results)\n        results.to_feather(file_path)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2dcaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}