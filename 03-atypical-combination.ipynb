{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1bbca9",
   "metadata": {},
   "source": [
    "### **Atypical Combination**\n",
    "\n",
    "Atypical combination measures how unconventional or novel a paper's combination of cited journals is. This approach uses permutation tests to establish a baseline expectation and calculate z-scores for journal pair co-citations.\n",
    "\n",
    "For each paper, we:\n",
    "1. Identify all pairs of journals cited together\n",
    "2. Generate a null distribution by shuffling cited journals across papers (preserving the year structure)\n",
    "3. Calculate z-scores comparing observed co-citation frequencies to the shuffled baseline\n",
    "4. Aggregate z-scores across all pairs (e.g., median, 10th percentile)\n",
    "\n",
    "Papers with lower z-scores (especially at the 10th percentile) cite journal combinations that are statistically unusual compared to what would be expected by chance. This captures the novelty of knowledge integration.\n",
    "\n",
    "**Reference:**\n",
    " - Uzzi, Brian, et al. \"Atypical combinations and scientific impact.\" Science 342.6157 (2013): 468-472."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "import json, os, shutil\n",
    "from operator import add\n",
    "from glob import glob\n",
    "import pickle as pkl\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "dict_paper_to_journal_id = pd.read_feather('intermediate/dict_paper_to_journal_id.feather')\n",
    "dict_paper_to_journal_id = dict_paper_to_journal_id.dropna(subset=[\"paper_id\", \"journal_id\"])\n",
    "dict_paper_to_journal_id = dict_paper_to_journal_id.set_index(\"paper_id\").journal_id.astype(int)\n",
    "\n",
    "pub_citing_cited_years = (\n",
    "    pd.read_feather(\"intermediate/citing_cited_paper_id_year.feather\")\n",
    "    .query(\"citing_year >= cited_year\")\n",
    ")\n",
    "\n",
    "pub_citing_cited_years[\"cited_journal_id\"] = (\n",
    "    pub_citing_cited_years[\"cited_paperid\"]\n",
    "    .map(dict_paper_to_journal_id)\n",
    ")\n",
    "\n",
    "ref_df = pub_citing_cited_years[pub_citing_cited_years.cited_journal_id.notna()]\n",
    "ref_df[\"cited_journal_id\"] = ref_df[\"cited_journal_id\"].astype(int)\n",
    "del dict_paper_to_journal_id, pub_citing_cited_years\n",
    "\n",
    "\n",
    "def observe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\tpair_counts = (\n",
    "\t\tdf.groupby(\"citing_paperid\")\n",
    "\t\t.cited_journal_id\n",
    "\t\t.apply(list)\n",
    "\t\t.map(lambda x: x if len(x) < 1000 else [])\n",
    "\t\t.map(lambda x: list(combinations(sorted(x), 2)))\n",
    "\t\t.explode()\n",
    "\t\t.dropna()\n",
    "\t\t.value_counts()\n",
    "\t)\n",
    "\treturn pair_counts\n",
    "\n",
    "def shuffle(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\tdf = df.copy()\n",
    "\tdf[\"cited_journal_id\"] = (\n",
    "\t\tdf.groupby(\"cited_year\", sort=False)['cited_journal_id']\n",
    "\t\t.transform(np.random.permutation)\n",
    "\t)\n",
    "\treturn df\n",
    "\n",
    "def calculate_z_score(save_path: str, year: int) -> pd.DataFrame:\n",
    "\tref_df_year = ref_df[ref_df.citing_year == year].reset_index(drop=True)\n",
    "\n",
    "\t# mean, m2 = None, None\n",
    "\t# for epoch in trange(10, ncols=100, mininterval=1):\n",
    "\t# \tprint(f\"Shuffling for year {year} at epoch {epoch}\")\n",
    "\t# \ts = observe(shuffle(ref_df_year))\n",
    "\t# \tif mean is None:\n",
    "\t# \t\tmean, m2 = s, s**2\n",
    "\t# \telse:\n",
    "\t# \t\tmean, m2 = mean.add(s, fill_value=0), m2.add(s**2, fill_value=0)\n",
    "\t# expected_freq_mean = mean / 10\n",
    "\t# expected_freq_std = np.sqrt(m2 / 10 - expected_freq_mean**2)\n",
    "\n",
    "\texpected_freq_df = []\n",
    "\tfor epoch in trange(10, ncols=100, mininterval=1, desc=f\"Shuffling\"):\n",
    "\t\texpected_freq_df.append(observe(shuffle(ref_df_year)))\n",
    "\texpected_freq_df = pd.DataFrame(expected_freq_df).T.fillna(0)\n",
    "\texpected_freq_mean = expected_freq_df.mean(axis=1)\n",
    "\texpected_freq_std = expected_freq_df.std(axis=1)\n",
    "\n",
    "\tobserved_freq = observe(ref_df_year)\n",
    "\tindex = pd.Index(observed_freq.index).intersection(expected_freq_std[expected_freq_std != 0].index)\n",
    "\tz_score_for_year = (observed_freq[index] - expected_freq_mean[index]) / expected_freq_std[index]\n",
    "\tz_score_for_year = defaultdict(lambda: None, z_score_for_year.dropna().to_dict())\n",
    "\n",
    "\tpaper_pairs = (\n",
    "\t\tref_df_year\n",
    "\t\t.groupby(\"citing_paperid\")\n",
    "\t\t.cited_journal_id.apply(list)\n",
    "\t\t.map(lambda x: set(combinations(sorted(x), 2)))\n",
    "\t\t.reset_index()\n",
    "\t)\n",
    "\n",
    "\tz_median_list = []\n",
    "\tz_10_pct_list = []\n",
    "\n",
    "\tfor _, row in tqdm(paper_pairs.iterrows(), total=len(paper_pairs), ncols=100, mininterval=1, desc=f\"Calculating z-score for year {year}\"):\n",
    "\t\tfocal_paper_id = row[\"citing_paperid\"]\n",
    "\t\tcited_journal_id = row[\"cited_journal_id\"]\n",
    "\t\t\n",
    "\t\tk = focal_paper_id\n",
    "\t\tz_for_k = [z_score_for_year.get(pair, None) for pair in cited_journal_id]\n",
    "\t\tz_for_k = [z for z in z_for_k if z is not None]\n",
    "\t\tif len(z_for_k) > 0:\n",
    "\t\t\tz_median_list.append([k, np.quantile(z_for_k, 0.5), len(z_for_k)])\n",
    "\t\t\tz_10_pct_list.append([k, np.quantile(z_for_k, 0.1), len(z_for_k)])\n",
    "\n",
    "\tz_10_pct_df = pd.DataFrame(z_10_pct_list, columns=[\"paper_id\", \"z_10_pct\", \"valid_pairs\"])\n",
    "\tz_median_df = pd.DataFrame(z_median_list, columns=[\"paper_id\", \"z_median\", \"valid_pairs\"])\n",
    "\n",
    "\tz_10_pct_df[\"paper_id\"] = \"pub.\" + z_10_pct_df[\"paper_id\"].astype(str)\n",
    "\tz_median_df[\"paper_id\"] = \"pub.\" + z_median_df[\"paper_id\"].astype(str)\n",
    "\n",
    "\tos.makedirs(save_path, exist_ok=True)\n",
    "\tz_10_pct_df.to_feather(f\"{save_path}/z_10_pct_{year}.feather\")\n",
    "\tz_median_df.to_feather(f\"{save_path}/z_median_{year}.feather\")\n",
    "\n",
    "\n",
    "save_path = 'intermediate/atypical-combination'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "years = list(range(1979, 2011))\n",
    "for year in tqdm(years, ncols=100, mininterval=1, desc=\"Z-score Calculation\"):\n",
    "\tcalculate_z_score(save_path, year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
