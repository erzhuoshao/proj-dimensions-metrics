{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1bbca9",
   "metadata": {},
   "source": [
    "### **Atypical Combination**\n",
    "\n",
    "Atypical combination measures how unconventional or novel a paper's combination of cited journals is. This approach uses permutation tests to establish a baseline expectation and calculate z-scores for journal pair co-citations.\n",
    "\n",
    "For each paper, we:\n",
    "1. Identify all pairs of journals cited together\n",
    "2. Generate a null distribution by shuffling cited journals across papers (preserving the year structure)\n",
    "3. Calculate z-scores comparing observed co-citation frequencies to the shuffled baseline\n",
    "4. Aggregate z-scores across all pairs (e.g., median, 10th percentile)\n",
    "\n",
    "Papers with lower z-scores (especially at the 10th percentile) cite journal combinations that are statistically unusual compared to what would be expected by chance. This captures the novelty of knowledge integration.\n",
    "\n",
    "**Reference:**\n",
    " - Uzzi, Brian, et al. \"Atypical combinations and scientific impact.\" Science 342.6157 (2013): 468-472."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562d917",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm, trange\ntqdm.pandas()\nimport json, os, shutil\nfrom operator import add\nfrom glob import glob\nimport pickle as pkl\nfrom itertools import combinations\nfrom collections import defaultdict\nfrom tqdm.contrib.concurrent import process_map\n\nfrom itertools import combinations\nfrom collections import defaultdict\n\ndict_paper_to_journal_id = pd.read_feather('intermediate/dict_paper_to_journal_id.feather')\ndict_paper_to_journal_id = dict_paper_to_journal_id.dropna(subset=[\"paper_id\", \"journal_id\"])\ndict_paper_to_journal_id = dict_paper_to_journal_id.set_index(\"paper_id\").journal_id.astype(int)\n\npub_citing_cited_years = (\n    pd.read_feather(\"intermediate/citing_cited_paper_id_year.feather\")\n    .query(\"citing_year >= cited_year\")\n)\n\npub_citing_cited_years[\"cited_journal_id\"] = (\n    pub_citing_cited_years[\"cited_paperid\"]\n    .map(dict_paper_to_journal_id)\n)\n\nref_df = pub_citing_cited_years[pub_citing_cited_years.cited_journal_id.notna()]\nref_df[\"cited_journal_id\"] = ref_df[\"cited_journal_id\"].astype(int)\ndel dict_paper_to_journal_id, pub_citing_cited_years\n\n\ndef observe(df: pd.DataFrame) -> pd.DataFrame:\n\tpair_counts = (\n\t\tdf.groupby(\"citing_paperid\")\n\t\t.cited_journal_id\n\t\t.apply(list)\n\t\t.map(lambda x: x if len(x) < 1000 else [])\n\t\t.map(lambda x: list(combinations(sorted(x), 2)))\n\t\t.explode()\n\t\t.dropna()\n\t\t.value_counts()\n\t)\n\treturn pair_counts\n\ndef shuffle(df: pd.DataFrame) -> pd.DataFrame:\n\tdf = df.copy()\n\tdf[\"cited_journal_id\"] = (\n\t\tdf.groupby(\"cited_year\", sort=False)['cited_journal_id']\n\t\t.transform(np.random.permutation)\n\t)\n\treturn df\n\ndef calculate_z_score(save_path: str, year: int) -> pd.DataFrame:\n\tref_df_year = ref_df[ref_df.citing_year == year].reset_index(drop=True)\n\n\texpected_freq_df = []\n\tfor epoch in trange(10, ncols=100, mininterval=1, desc=f\"Shuffling\"):\n\t\texpected_freq_df.append(observe(shuffle(ref_df_year)))\n\texpected_freq_df = pd.DataFrame(expected_freq_df).T.fillna(0)\n\texpected_freq_mean = expected_freq_df.mean(axis=1)\n\texpected_freq_std = expected_freq_df.std(axis=1)\n\n\tobserved_freq = observe(ref_df_year)\n\tindex = pd.Index(observed_freq.index).intersection(expected_freq_std[expected_freq_std != 0].index)\n\tz_score_for_year = (observed_freq[index] - expected_freq_mean[index]) / expected_freq_std[index]\n\tz_score_for_year = defaultdict(lambda: None, z_score_for_year.dropna().to_dict())\n\n\tpaper_pairs = (\n\t\tref_df_year\n\t\t.groupby(\"citing_paperid\")\n\t\t.cited_journal_id.apply(list)\n\t\t.map(lambda x: set(combinations(sorted(x), 2)))\n\t\t.reset_index()\n\t)\n\n\tz_median_list = []\n\tz_10_pct_list = []\n\n\tfor row in tqdm(paper_pairs.itertuples(), total=len(paper_pairs), ncols=100, mininterval=1, desc=f\"Calculating z-score for year {year}\"):\n\t\tfocal_paper_id = row.citing_paperid\n\t\tcited_journal_id = row.cited_journal_id\n\t\t\n\t\tk = focal_paper_id\n\t\tz_for_k = [z_score_for_year.get(pair, None) for pair in cited_journal_id]\n\t\tz_for_k = [z for z in z_for_k if z is not None]\n\t\tif len(z_for_k) > 0:\n\t\t\tz_median_list.append([k, np.quantile(z_for_k, 0.5), len(z_for_k)])\n\t\t\tz_10_pct_list.append([k, np.quantile(z_for_k, 0.1), len(z_for_k)])\n\n\tz_10_pct_df = pd.DataFrame(z_10_pct_list, columns=[\"paper_id\", \"z_10_pct\", \"valid_pairs\"])\n\tz_median_df = pd.DataFrame(z_median_list, columns=[\"paper_id\", \"z_median\", \"valid_pairs\"])\n\n\tz_10_pct_df[\"paper_id\"] = \"pub.\" + z_10_pct_df[\"paper_id\"].astype(str)\n\tz_median_df[\"paper_id\"] = \"pub.\" + z_median_df[\"paper_id\"].astype(str)\n\n\tos.makedirs(save_path, exist_ok=True)\n\tz_10_pct_df.to_feather(f\"{save_path}/z_10_pct_{year}.feather\")\n\tz_median_df.to_feather(f\"{save_path}/z_median_{year}.feather\")\n\n\nsave_path = 'intermediate/atypical-combination'\nos.makedirs(save_path, exist_ok=True)\nyears = list(range(1979, 2011))\nfor year in tqdm(years, ncols=100, mininterval=1, desc=\"Z-score Calculation\"):\n\tcalculate_z_score(save_path, year)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}