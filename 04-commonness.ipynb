{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Commonness**\n",
    "\n",
    "Commonness is a simplified measure of how typical or conventional a paper's combination of cited journals is. Unlike the atypical combination measure (which uses permutation tests to calculate z-scores), commonness directly uses the co-occurrence probability of journal pairs.\n",
    "\n",
    "For each paper, we:\n",
    "1. Identify all pairs of journals cited together\n",
    "2. Look up the empirical probability that these two journals are co-cited (based on historical data)\n",
    "3. Take the negative log of these probabilities (lower probability = higher novelty)\n",
    "4. Aggregate across all pairs (e.g., median, mean, percentiles)\n",
    "\n",
    "This approach is computationally simpler than atypical combination because it doesn't require shuffling/permutation tests, but captures a similar concept: papers that cite unusual combinations of journals together.\n",
    "\n",
    "**Reference:**\n",
    " - Lee, You-Na, John P. Walsh, and Jian Wang. \"Creativity in scientific teams: Unpacking novelty and impact.\" Research policy 44.3 (2015): 684-697."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "from matplotlib import pyplot as plt\n",
    "import json, os, shutil\n",
    "from operator import add\n",
    "from glob import glob\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_paper_to_journal_id = pd.read_feather('intermediate/dict_paper_to_journal_id.feather')\n",
    "dict_paper_to_journal_id = dict_paper_to_journal_id.set_index(\"paper_id\")[\"journal_id\"].to_dict()\n",
    "print(f'len(dict_paper_to_journal_id) = {len(dict_paper_to_journal_id)}')\n",
    "\n",
    "dict_year_to_paper_ids = pd.read_feather('intermediate/dict_year_to_paper_ids.feather')\n",
    "dict_year_to_paper_ids = dict_year_to_paper_ids.set_index(\"year\")[\"paper_ids\"].to_dict()\n",
    "print(f'len(dict_year_to_paper_ids) = {len(dict_year_to_paper_ids)}')\n",
    "\n",
    "dict_citing_to_cited = pd.read_feather('data/dict_citing_to_cited_id_and_year.feather')\n",
    "dict_citing_to_cited = dict_citing_to_cited.set_index(\"citing_paperid\").cited_list.progress_map(lambda x: [i[0] for i in x]).to_dict()\n",
    "print(f'len(dict_citing_to_cited) = {len(dict_citing_to_cited)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "def process_subset(args):\n",
    "    citing_paper_ids, year = args\n",
    "    N_i_j_t, N_i_t, N_j_t, N_t = Counter(), Counter(), Counter(), Counter()\n",
    "\n",
    "    for citing_paper_id in tqdm(citing_paper_ids, ncols=100, mininterval=1, desc=f'Processing year {year}'):\n",
    "        # Get the cited paper IDs for the current citing paper ID\n",
    "        cited_journals = []\n",
    "        for cited_paper_id in dict_citing_to_cited.get(citing_paper_id, []):\n",
    "            cited_journal_id = dict_paper_to_journal_id.get(cited_paper_id, None)\n",
    "            if cited_journal_id != None:\n",
    "                cited_journals.append(cited_journal_id)\n",
    "\n",
    "        cited_journal_pairs = [(year, i, j) for i, j in combinations(sorted(cited_journals), r=2)]\n",
    "        for t, i, j in cited_journal_pairs:\n",
    "            N_i_j_t[(i, j, t)] = N_i_j_t.get((i, j, t), 0) + 1\n",
    "\n",
    "    for (i, j, t), n_i_j_t in N_i_j_t.items():\n",
    "        N_i_t[(i, t)] = N_i_t.get((i, t), 0) + n_i_j_t\n",
    "        N_j_t[(j, t)] = N_j_t.get((j, t), 0) + n_i_j_t\n",
    "        N_t[t] = N_t.get(t, 0) + n_i_j_t\n",
    "    return N_i_j_t, N_i_t, N_j_t, N_t\n",
    "\n",
    "tasks = [(dict_year_to_paper_ids[year], year) for year in sorted(dict_year_to_paper_ids.keys())]\n",
    "results = process_map(process_subset, tasks, max_workers=40, chunksize=1000)\n",
    "\n",
    "\n",
    "N_i_j_t, N_i_t, N_j_t, N_t = Counter(), Counter(), Counter(), Counter()\n",
    "for local_i_j_t, local_i_t, local_j_t, local_t in tqdm(results, ncols=100, mininterval=1):\n",
    "    N_i_j_t += local_i_j_t\n",
    "    N_i_t   += local_i_t\n",
    "    N_j_t   += local_j_t\n",
    "    N_t     += local_t\n",
    "    \n",
    "commonness_i_j_t = {}\n",
    "for (i, j, t) in tqdm(N_i_j_t.keys(), ncols=100, mininterval=1):\n",
    "    n_i_j_t, n_i_t, n_j_t, n_t = N_i_j_t[(i, j, t)], N_i_t[(i, t)], N_j_t[(j, t)], N_t[t]\n",
    "    commonness_i_j_t[(i, j, t)] = {\n",
    "        'N_i_j_t': n_i_j_t, 'N_i_t': n_i_t, 'N_j_t': n_j_t, 'N_t': n_t,\n",
    "        'commonness': n_i_j_t * n_t / (n_i_t * n_j_t)\n",
    "    }\n",
    "\n",
    "print(\"Transforming to Dataframe\")\n",
    "df_commonness = pd.DataFrame.from_dict(commonness_i_j_t, orient='index').reset_index()\n",
    "df_commonness.columns = ['journal_id_1', 'journal_id_2', 'year', 'N_i_j_t', 'N_i_t', 'N_j_t', 'N_t', 'commonness']\n",
    "\n",
    "print(\"Transforming to Dataframe\")\n",
    "df_commonness.to_csv('data/commonness_journal_pairs.tsv', sep='\\t', index=False)\n",
    "df_commonness.to_feather('data/commonness_journal_pairs.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonness_i_j_t = pd.read_csv(\n",
    "    'data/commonness_journal_pairs.tsv', sep='\\t'\n",
    ").set_index(['journal_id_1', 'journal_id_2', 'year']).commonness.to_dict()\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "def calculate_commonness(args):\n",
    "    citing_paper_id, year = args\n",
    "    cited_journals = []\n",
    "    for cited_paper_id in dict_citing_to_cited.get(citing_paper_id, []):\n",
    "        cited_journal_id = dict_paper_to_journal_id.get(cited_paper_id, None)\n",
    "        if cited_journal_id is not None:\n",
    "            cited_journals.append(cited_journal_id)\n",
    "\n",
    "    cited_journal_pairs = [(i, j, year) for i, j in combinations(sorted(cited_journals), r=2)]\n",
    "    if not cited_journal_pairs:\n",
    "        return None\n",
    "\n",
    "    commonness_values = np.array(\n",
    "        [commonness_i_j_t[(i, j, year)] for i, j, year in cited_journal_pairs if (i, j, year) in commonness_i_j_t])\n",
    "\n",
    "    if len(commonness_values) == 0:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"year\": year,\n",
    "        \"paper_id\": f\"pub.{citing_paper_id}\",\n",
    "        '1_pct_commonness': -np.log(np.quantile(commonness_values, 0.01)),\n",
    "        '5_pct_commonness': -np.log(np.quantile(commonness_values, 0.05)),\n",
    "        '10_pct_commonness': -np.log(np.quantile(commonness_values, 0.10)),\n",
    "        '25_pct_commonness': -np.log(np.quantile(commonness_values, 0.25)),\n",
    "        'median_commonness': -np.log(np.quantile(commonness_values, 0.50)),\n",
    "        'mean_commonness_mean': np.mean(-np.log(commonness_values)),\n",
    "        'std_commonness_std': np.std(-np.log(commonness_values)),\n",
    "        \"valid_pairs\": len(cited_journal_pairs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for year, citing_paper_ids in dict_year_to_paper_ids.items():\n",
    "    tasks.extend([(citing_paper_id, year) for citing_paper_id in citing_paper_ids])\n",
    "\n",
    "paper_commonness = process_map(calculate_commonness, tasks, max_workers=40, chunksize=1000)\n",
    "paper_commonness = [r for r in paper_commonness if r is not None]\n",
    "\n",
    "df_paper_commonness = pd.DataFrame(paper_commonness)\n",
    "df_paper_commonness.to_csv('data/commonness.tsv', sep='\\t', index=False)\n",
    "df_paper_commonness.to_feather('data/commonness.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
