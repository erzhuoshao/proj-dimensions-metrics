{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb19749",
   "metadata": {},
   "source": [
    "### **Multidisciplinary Index**\n",
    "\n",
    "**Reference:**\n",
    " - Zeng, An, et al. \"Fresh teams are associated with original and multidisciplinary research.\" Nature human behaviour 5.10 (2021): 1314-1322."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2885d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import json, pickle as pkl\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import product, combinations\n",
    "from copy import deepcopy\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "import shutil, os\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas(ncols=100, mininterval=1)\n",
    "tqdm, trange = partial(tqdm, ncols=100, mininterval=1), partial(trange, ncols=100, mininterval=1)\n",
    "\n",
    "\n",
    "references = pd.read_feather('intermediate/citing_cited_paper_id_year.feather')\n",
    "\n",
    "papers = pd.read_parquet('../parquet/processed/publications.parquet')\n",
    "papers['id'] = papers['id'].str[4:].astype(int)\n",
    "\n",
    "paper_to_date = papers[['id', 'date']][lambda x: x.date.str.len() == 10]\n",
    "paper_to_date.columns = ['citing_paperid', 'citing_paper_date']\n",
    "references = references.merge(paper_to_date, on='citing_paperid', how='left')\n",
    "\n",
    "paper_to_future_citation_sequence = (\n",
    "    references\n",
    "    .dropna(subset=[\"citing_paper_date\"])\n",
    "    .sort_values(by=[\"citing_paper_date\"], ascending=True)\n",
    "    .reset_index(drop=True)\n",
    "    .groupby(\"cited_paperid\")\n",
    "    [[\"citing_paperid\", \"citing_paper_date\"]]\n",
    "    .apply(lambda x: x.values.tolist())\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "# Dict Structure: {citing_paperid (int): citing_year (int)}\n",
    "dict_paper_id_to_year = papers.set_index('id').date.to_dict()\n",
    "\n",
    "# Dict Structure: {citing_paperid (int): [list of cited_paperids (int)]}\n",
    "dict_citing_to_cited = (\n",
    "    references\n",
    "    .groupby('citing_paperid')\n",
    "    .cited_paperid\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "def paper_id_to_multidisciplinary(focal_paper_id):\n",
    "    # [[citing_paperid, citing_year], ...]\n",
    "\n",
    "    citing_paper_id_year_list = paper_to_future_citation_sequence.get(focal_paper_id, [])\n",
    "    if len(citing_paper_id_year_list) >= 5:\n",
    "        l = []\n",
    "        for i in range(len(citing_paper_id_year_list) - 1):\n",
    "            citing_paper_id1, citing_paper_year1 = citing_paper_id_year_list[i]\n",
    "            citing_paper_id2, citing_paper_year2 = citing_paper_id_year_list[i + 1]\n",
    "\n",
    "            ref1 = set(dict_citing_to_cited[citing_paper_id1])\n",
    "            ref2 = set(dict_citing_to_cited[citing_paper_id2])\n",
    "            ref1_without_focal = ref1 - {focal_paper_id}\n",
    "            ref2_without_focal = ref2 - {focal_paper_id}\n",
    "            not_share_ref = len(ref1_without_focal & ref2_without_focal) == 0\n",
    "            l.append(not_share_ref)\n",
    "        return (focal_paper_id, np.mean(l))\n",
    "    else:\n",
    "        return (focal_paper_id, None)\n",
    "\n",
    "\n",
    "\n",
    "focal_paper_ids = list(paper_to_future_citation_sequence.keys())\n",
    "\n",
    "batch_size = 500_000\n",
    "results = []\n",
    "for idx in trange(0, len(focal_paper_ids), batch_size):\n",
    "    results += process_map(paper_id_to_multidisciplinary, focal_paper_ids[idx:idx+batch_size], max_workers=20, chunksize=1000)\n",
    "multidisciplinary_df = pd.DataFrame(results, columns=['paper_id', 'multidisciplinary'])\n",
    "multidisciplinary_df[\"paper_id\"] = \"pub.\" + multidisciplinary_df[\"paper_id\"].astype(str)\n",
    "\n",
    "multidisciplinary_df.to_csv('data/multidisciplinary.tsv', sep='\\t', index=False)\n",
    "multidisciplinary_df.to_parquet(\"data/multidisciplinary.parquet\")\n",
    "multidisciplinary_df.to_feather(\"data/multidisciplinary.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30207f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57b431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
