{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b597af5",
   "metadata": {},
   "source": [
    "### Atypical Combination\n",
    " - Brian Uzzi et al. ,Atypical Combinations and Scientific Impact.Science342,468-472(2013).DOI:10.1126/science.1240474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "from matplotlib import pyplot as plt\n",
    "import json, os, shutil\n",
    "from operator import add\n",
    "from glob import glob\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time atyp_comb_2025 = pd.concat([pd.read_parquet(f\"intermediate/atypical-combination-2/z_10_pct/{year}.parquet\") for year in trange(1800, 1930)])\n",
    "# atyp_comb_2025 = pd.concat([\n",
    "#     pd.read_parquet(f\"intermediate/atypical-combination-2/z_10_pct/{year}.parquet\")\n",
    "#     for year in trange(2011, 2015)\n",
    "# ])\n",
    "atyp_comb_3 = pd.read_feather(\"intermediate/atypical-combination-zihang-3/z_10_pct_1950.feather\")\n",
    "atyp_comb_3[\"paper_id\"] = atyp_comb_3[\"paper_id\"].str[4:].astype(int)\n",
    "atyp_comb_3.columns = ['paper_id', 'atyp_comb_3', 'valid_pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7774482",
   "metadata": {},
   "outputs": [],
   "source": [
    "atyp_comb_2 = pd.read_feather(\"intermediate/atypical-combination-2/z_10_pct_1960.feather\")\n",
    "atyp_comb_2[\"paper_id\"] = atyp_comb_2[\"paper_id\"].str[4:].astype(int)\n",
    "atyp_comb_2.columns = ['paper_id', 'atyp_comb_2', 'valid_pairs']\n",
    "\n",
    "atyp_comb_1 = pd.read_feather(\"intermediate/atypical-combination-21/z_10_pct_1960.feather\")\n",
    "atyp_comb_1[\"paper_id\"] = atyp_comb_1[\"paper_id\"].str[4:].astype(int)\n",
    "atyp_comb_1.columns = ['paper_id', 'atyp_comb_1', 'valid_pairs']\n",
    "\n",
    "combination = atyp_comb_1.merge(atyp_comb_2, on=\"paper_id\", how=\"inner\")\n",
    "print(combination[[\"valid_pairs_x\", \"valid_pairs_y\"]].corr())\n",
    "print(combination[[\"atyp_comb_1\", \"atyp_comb_2\"]].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = atyp_comb_2.merge(atyp_comb_3, on=\"paper_id\", how=\"inner\")\n",
    "print(combination[[\"valid_pairs_x\", \"valid_pairs_y\"]].corr())\n",
    "print(combination[[\"atyp_comb_2\", \"atyp_comb_3\"]].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "atyp_comb_1 = pd.read_feather(\"/kellogg/proj/dashun/dimensions/data_dump/20230910/tsv/Metrics/Z_10_pct_Atyp_Comb.feather\")\n",
    "atyp_comb_1.columns = ['paper_id', 'atyp_comb_1', 'valid_pairs']\n",
    "\n",
    "atyp_comb_2 = pd.read_feather(\"intermediate/atypical-combination/z_10_pct_2011.feather\")\n",
    "atyp_comb_2[\"paper_id\"] = atyp_comb_2[\"paper_id\"].str[4:].astype(int)\n",
    "atyp_comb_2.columns = ['paper_id', 'atyp_comb_2', 'valid_pairs']\n",
    "\n",
    "combination = atyp_comb_1.merge(atyp_comb_2, on=\"paper_id\", how=\"inner\")\n",
    "print(combination[[\"valid_pairs_x\", \"valid_pairs_y\"]].corr(method='spearman'))\n",
    "print(combination[[\"atyp_comb_1\", \"atyp_comb_2\"]].corr(method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "atyp_comb_1 = pd.read_feather(\"/kellogg/proj/dashun/dimensions/data_dump/20230910/tsv/Metrics/Z_10_pct_Atyp_Comb.feather\")\n",
    "atyp_comb_1.columns = ['paper_id', 'atyp_comb_1', 'valid_pairs']\n",
    "\n",
    "atyp_comb_2 = pd.read_feather(\"intermediate/atypical-combination/z_10_pct_2011.feather\")\n",
    "atyp_comb_2[\"paper_id\"] = atyp_comb_2[\"paper_id\"].str[4:].astype(int)\n",
    "atyp_comb_2.columns = ['paper_id', 'atyp_comb_2', 'valid_pairs']\n",
    "\n",
    "combination = atyp_comb_1.merge(atyp_comb_2, on=\"paper_id\", how=\"inner\")\n",
    "print(combination[[\"valid_pairs_x\", \"valid_pairs_y\"]].corr(method='spearman'))\n",
    "print(combination[[\"atyp_comb_1\", \"atyp_comb_2\"]].corr(method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd749bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d23a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the feather files\n",
    "disruptiveness_dir = \"/kellogg/proj/dashun/dimensions/data_dump/20250221/erzhuo/intermediate/disruptiveness\"\n",
    "\n",
    "# Get all feather files in the directory\n",
    "import glob\n",
    "feather_files = glob.glob(os.path.join(disruptiveness_dir, '*.feather'))\n",
    "\n",
    "# Read and concatenate all feather files\n",
    "from tqdm import tqdm\n",
    "\n",
    "dfs = []\n",
    "for file in tqdm(feather_files):\n",
    "    file_path = os.path.join(disruptiveness_dir, file)\n",
    "    df = pd.read_feather(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "disruptiveness_combined = pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "print(f\"Total rows: {len(disruptiveness_combined)}\")\n",
    "print(f\"Columns: {disruptiveness_combined.columns.tolist()}\")\n",
    "print(disruptiveness_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ed530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined disruptiveness data\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save as feather\n",
    "disruptiveness_combined.to_feather(os.path.join(output_dir, \"disruptiveness.feather\"))\n",
    "\n",
    "# Save as tsv\n",
    "disruptiveness_combined.to_csv(os.path.join(output_dir, \"disruptiveness.tsv\"), sep='\\t', index=False)\n",
    "\n",
    "print(f\"Saved disruptiveness data to {output_dir}/disruptiveness.feather and {output_dir}/disruptiveness.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d96c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc4c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c9d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92556e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the old and new z_10_pct values\n",
    "values_2023 = combination[\"atyp_comb_2023\"].values\n",
    "values_2025 = combination[\"atyp_comb_2025\"].values\n",
    "\n",
    "# Create figure\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# Function to create CDF with log scale for both positive and negative parts\n",
    "def plot_cdf_symlog(ax, values, label, color):\n",
    "    # Sort values\n",
    "    sorted_vals = np.sort(values)\n",
    "    # Create CDF y-values\n",
    "    y = np.arange(1, len(sorted_vals) + 1) / len(sorted_vals)\n",
    "    \n",
    "    # Plot CDF\n",
    "    ax.plot(sorted_vals, y, label=label, color=color, linewidth=2)\n",
    "    ax.set_xscale('symlog', linthresh=4, base=2)\n",
    "    ax.set_xlabel('Atypical Combination Z-score')\n",
    "    ax.set_ylabel('Cumulative Probability')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plot_cdf_symlog(ax1, values_2023, '2023 Atypical Combination', 'blue')\n",
    "plot_cdf_symlog(ax1, values_2025, '2025 Atypical Combination', 'red')\n",
    "ax1.set_title('CDF Comparison: 2023 vs 2025 Atypical Combination')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some summary statistics\n",
    "print(f\"Old values - Min: {values_2023.min():.3f}, Max: {values_2023.max():.3f}, Median: {np.median(values_2023):.3f}\")\n",
    "print(f\"New values - Min: {values_2025.min():.3f}, Max: {values_2025.max():.3f}, Median: {np.median(values_2025):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038d9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38deeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319061b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
