{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73535989",
   "metadata": {},
   "source": [
    "### **Rao-Stirling Diversity Index**\n",
    "\n",
    "The Rao-Stirling diversity index measures the interdisciplinarity of a paper based on the variety and balance of fields represented in its references, weighted by the cognitive distance between those fields.\n",
    "\n",
    "For each paper, we:\n",
    "1. Identify the fields of all cited references\n",
    "2. Calculate the proportion of references in each field (variety and balance)\n",
    "3. Compute pairwise distances between fields based on their cognitive dissimilarity\n",
    "4. Calculate the Rao-Stirling index as the sum of (proportion_i × proportion_j × distance_ij) across all field pairs\n",
    "\n",
    "This approach captures both the diversity of fields cited and how cognitively distant those fields are from each other. Papers citing references from many distant fields will have higher Rao-Stirling scores.\n",
    "\n",
    "**Reference:**\n",
    " - Park, Minsu, et al. \"Interdisciplinary Papers Supported by Disciplinary Grants Garner Deep and Broad Scientific Impact.\" arXiv preprint arXiv:2303.14732 (2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas(ncols=100, mininterval=1)\n",
    "tqdm, trange = partial(tqdm, ncols=100, mininterval=1), partial(trange, ncols=100, mininterval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902268df",
   "metadata": {},
   "outputs": [],
   "source": "field_l0_list = list(pd.read_csv('intermediate/ANZSRC_FoR.tsv', sep='\\t')['Field L0 Code'].drop_duplicates())\nfield_l0_dict = {field_l0_list[i]:i for i in range(len(field_l0_list))}\nfield_l1_list = list(pd.read_csv('intermediate/ANZSRC_FoR.tsv', sep='\\t')['Field L1 Code'].drop_duplicates())\nfield_l1_dict = {field_l1_list[i]:i for i in range(len(field_l1_list))}\n\n\n\npapers = pd.read_parquet('../parquet/processed/publications.parquet').dropna(subset=['num_references', 'date'])\npapers['year'] = papers['date'].str[:4].astype(int)\npapers['id'] = papers['id'].str[4:].astype(int)\nprint(f\"# Papers: {len(papers)}\")\n\npaper_field_l0 = pd.read_parquet('../parquet/processed/paper_fields_l0.parquet')[[\"paper_id\", \"l0_code\"]].drop_duplicates(subset=['paper_id'], keep='first')\npaper_field_l1 = pd.read_parquet('../parquet/processed/paper_fields_l1.parquet')[[\"paper_id\", \"l1_code\"]].drop_duplicates(subset=['paper_id'], keep='first')\npaper_field_l0['paper_id'] = paper_field_l0['paper_id'].str[4:].astype(int)\npaper_field_l1['paper_id'] = paper_field_l1['paper_id'].str[4:].astype(int)\n\n\npapers[\"l0_code\"] = papers.id.map(paper_field_l0.set_index('paper_id')[\"l0_code\"])\npapers[\"l1_code\"] = papers.id.map(paper_field_l1.set_index('paper_id')[\"l1_code\"])\npapers[\"l0_code_norm\"] = papers[\"l0_code\"].astype(pd.Int64Dtype()).map(field_l0_dict).astype(pd.Int64Dtype())\npapers[\"l1_code_norm\"] = papers[\"l1_code\"].astype(pd.Int64Dtype()).map(field_l1_dict).astype(pd.Int64Dtype())\n\npapers_dict = papers.set_index('id')[['year', 'l0_code_norm', 'l1_code_norm']].to_dict(orient='index')\n\n\n\n\ndf_citing_to_cited = pd.read_feather('intermediate/dict_citing_to_cited_id_and_year.feather')\n\nfield_l0_citation_matrix = np.zeros([2030, len(field_l0_dict), len(field_l0_dict)])\nfield_l1_citation_matrix = np.zeros([2030, len(field_l1_dict), len(field_l1_dict)])\n\nfor row in tqdm(df_citing_to_cited.itertuples(index=False), total=len(df_citing_to_cited)):\n    citing_paper_id, cited_paper_id_year_list = row.citing_paperid, row.cited_list\n    for cited_paper_id, year in cited_paper_id_year_list:\n        x_dict = papers_dict.get(int(citing_paper_id), {'year': None, 'l0_code_norm': None, 'l1_code_norm': None})\n        y_dict = papers_dict.get(int(cited_paper_id), {'year': None, 'l0_code_norm': None, 'l1_code_norm': None})\n\n        x_t, x_f_l0, x_f_l1 = x_dict['year'], x_dict['l0_code_norm'], x_dict['l1_code_norm']\n        y_t, y_f_l0, y_f_l1 = y_dict['year'], y_dict['l0_code_norm'], y_dict['l1_code_norm']\n        \n        if (x_t != None):\n            if (x_f_l0 != None) and (y_f_l0 != None):\n                field_l0_citation_matrix[x_t, x_f_l0, y_f_l0] += 1\n            if (x_f_l1 != None) and (y_f_l1 != None):\n                field_l1_citation_matrix[x_t, x_f_l1, y_f_l1] += 1\n                \nnp.save('data/field_l0_citation_matrix.npy', field_l0_citation_matrix)\nnp.save('data/field_l1_citation_matrix.npy', field_l1_citation_matrix)\n\nfrom scipy.spatial.distance import pdist, squareform\nfield_l0_citation_distance = np.zeros_like(field_l0_citation_matrix)\nfor year in trange(1800, 2030, desc=\"Computing L0 distances\"):\n    citation_vectors = field_l0_citation_matrix[year, :, :]\n    # pdist computes pairwise distances efficiently, squareform converts to square matrix\n    dist_matrix = squareform(pdist(citation_vectors, metric='cosine'))\n    # Handle NaN values (can occur when a field has no citations)\n    dist_matrix = np.nan_to_num(dist_matrix, nan=0.0)\n    # Ensure diagonal is zero\n    np.fill_diagonal(dist_matrix, 0)\n    field_l0_citation_distance[year, :, :] = dist_matrix\n\nnp.save('data/field_l0_citation_distance.npy', field_l0_citation_distance)\n\n\nfield_l1_citation_distance = np.zeros_like(field_l1_citation_matrix)\nfor year in trange(1800, 2030, desc=\"Computing L1 distances\"):\n    citation_vectors = field_l1_citation_matrix[year, :, :]\n    dist_matrix = squareform(pdist(citation_vectors, metric='cosine'))\n    dist_matrix = np.nan_to_num(dist_matrix, nan=0.0)\n    np.fill_diagonal(dist_matrix, 0)\n    field_l1_citation_distance[year, :, :] = dist_matrix\n\nnp.save('data/field_l1_citation_distance.npy', field_l1_citation_distance)\n\n\n\n\ndict_citing_to_cited_id_year_field = []\n\nfor row in tqdm(df_citing_to_cited.itertuples(index=False), total=len(df_citing_to_cited)):\n    cited_year_list, cited_paper_id_list, cited_field_l0_list, cited_field_l1_list = [], [], [], []\n    citing_paper_id, cited_paper_id_year_list = row.citing_paperid, row.cited_list\n    for cited_paper_id, year in cited_paper_id_year_list:\n        y_dict = papers_dict.get(int(cited_paper_id), {'year': None, 'l0_code_norm': None, 'l1_code_norm': None})\n        y_t, y_f_l0, y_f_l1 = y_dict['year'], y_dict['l0_code_norm'], y_dict['l1_code_norm']\n\n        cited_year_list.append(y_t)\n        cited_paper_id_list.append(cited_paper_id)\n        cited_field_l0_list.append(y_f_l0)\n        cited_field_l1_list.append(y_f_l1)\n    \n    dict_citing_to_cited_id_year_field.append([citing_paper_id, cited_paper_id_list, cited_year_list, cited_field_l0_list, cited_field_l1_list])\n    \ndict_citing_to_cited_id_year_field = pd.DataFrame(dict_citing_to_cited_id_year_field, columns=['citing_paper_id', 'cited_paper_id_list', 'cited_paper_year_list', 'cited_paper_field_l0_list', 'cited_paper_field_l1_list'])\n\ndict_citing_to_cited_id_year_field['citing_paper_year'] = dict_citing_to_cited_id_year_field.citing_paper_id.progress_map(\n    lambda x:papers_dict.get(int(x), {'year': None})[\"year\"])\n    \ndef filter_none(x):\n    return list(filter(lambda y:y is not None, x))\ndict_citing_to_cited_id_year_field[\"cited_paper_field_l0_list\"] = dict_citing_to_cited_id_year_field[\"cited_paper_field_l0_list\"].progress_map(filter_none)\ndict_citing_to_cited_id_year_field[\"cited_paper_field_l1_list\"] = dict_citing_to_cited_id_year_field[\"cited_paper_field_l1_list\"].progress_map(filter_none)\n\ndict_citing_to_cited_id_year_field.to_parquet('intermediate/dict_citing_to_cited_id_year_field.parquet')\ndict_citing_to_cited_id_year_field.to_feather('intermediate/dict_citing_to_cited_id_year_field.feather')\n\n\npaper_df = dict_citing_to_cited_id_year_field.dropna(subset=['citing_paper_year']).reset_index(drop=True)\nl0_data = list(zip(paper_df['cited_paper_field_l0_list'], paper_df['citing_paper_year']))\nl1_data = list(zip(paper_df['cited_paper_field_l1_list'], paper_df['citing_paper_year']))\n\n\ndef paper_to_rsd_l0(row):\n    cited_field_l0_list, year = row\n    if len(cited_field_l0_list) >= 5:\n        valid_fields = [i for i in cited_field_l0_list if i >= 0]\n        if len(valid_fields) == 0:\n            return None\n        field_l0_dist = np.bincount(valid_fields, minlength=len(field_l0_dict)).astype(float)\n        total = field_l0_dist.sum()\n        if total == 0:\n            return None\n        field_l0_dist /= total\n        return 2 * np.sum(field_l0_dist @ field_l0_citation_distance[int(year)] @ field_l0_dist)\n    else:\n        return None\n\ndef paper_to_rsd_l1(row):\n    cited_field_l1_list, year = row\n    if len(cited_field_l1_list) >= 5:\n        valid_fields = [i for i in cited_field_l1_list if i >= 0]\n        if len(valid_fields) == 0:\n            return None\n        field_l1_dist = np.bincount(valid_fields, minlength=len(field_l1_dict)).astype(float)\n        total = field_l1_dist.sum()\n        if total == 0:\n            return None\n        field_l1_dist /= total\n        return 2 * np.sum(field_l1_dist @ field_l1_citation_distance[int(year)] @ field_l1_dist)\n    else:\n        return None\n\n\n\n\nprint(\"Computing Rao-Stirling diversity L0...\")\npaper_df['rao_stirling_diversity_field_l0'] = process_map(\n    paper_to_rsd_l0, l0_data, max_workers=20, chunksize=1000)\n\nprint(\"Computing Rao-Stirling diversity L1...\")\npaper_df['rao_stirling_diversity_field_l1'] = process_map(\n    paper_to_rsd_l1, l1_data, max_workers=20, chunksize=1000)\n\npaper_df = paper_df[['citing_paper_id', 'citing_paper_year', 'rao_stirling_diversity_field_l0', 'rao_stirling_diversity_field_l1']]\npaper_df.columns = [\"id\", \"year\", \"rao_stirling_diversity_field_l0\", \"rao_stirling_diversity_field_l1\"]\n\npaper_df.to_parquet('data/rao_stirling_diversity.parquet')\npaper_df.to_feather('data/rao_stirling_diversity.feather')\npaper_df.to_csv('data/rao_stirling_diversity.tsv', sep='\\t', index=False)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}